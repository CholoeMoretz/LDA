对话英伟达加速计算高管：首次实现实时会话式AI，GPU优势是全可编程
原标题：对话英伟达加速计算高管：首次实现实时会话式AI，GPU优势是全可编程    来源：智东西
文 | 心缘
智东西12月18日苏州报道，今天上午NVIDIA创始人兼CEO黄仁勋在GTC China大会的主题演讲中，公布在会话式AI和推荐系统方面的重要进展。（黄仁勋推新自动驾驶芯片！性能飙升7倍，牵手BAT滴滴大秀中国朋友圈）
下午，NVIDIA加速计算产品管理总监Paresh Kharya、NVIDIA企业边缘计算总经理Justin Boitano、NVIDIA TensorRT产品市场负责人Siddarth Sharma接受智东西等媒体的采访，就NVIDIA深度学习产品进行更具体的解读。
Paresh Kharya表示，最终客户最在乎能否用各种计算平台来帮助他们降低成本、处理各种工作负载，同时不仅可以在今天利用这些硬件处理这些工作负载，并且在未来也能够持续。要实现这一点，软件定义平台非常重要。
一、进军会话式AI，数月覆盖完成流程
今天，NVIDIA推出第七代推理优化软件TensorRT 7。Paresh Kharya说，这是NVIDIA第一次真正实现实时会话式AI，并且可以准确的处理中间复杂的流程。
会话式AI是非常难的领域，要想把会话式AI做得比较有用，要符合两个条件。首先是要在300毫秒内将整个三个部分完成，其次是要完成的非常智能。
在这个过程当中，有非常多复杂的模型需要计算。会话式AI全流程有三个部分：语音识别、语义理解和转译、语音合成与输出。
据悉，NVIDIA做会话式AI已有数月时间，第一个版本只涵盖了会话式AI当中的语义理解部分。
在不断更新版本后，如今NVIDIA TensorRT 7基本上可以完成整个流程的计算。
二、GPU的优势：全可编程且软件定义
在Paresh Kharya看来，FPGA从设计时就是为模拟而用的，但是如果一个东西专为模拟而生，那么在真正实际应用过程中，它的表现反而可能没有那么好。
做好一个FPGA，整个编程的时间就要几个月，然后还要做在硬件层面对它进行编程。而AI演进速度飞快，甚至以分钟计，因此必须在软件端实现高度灵活的可编程。
Paresh Kharya表示，GPU是AI领域的专用芯片，其指令集是全可编程且软件定义的，非常具有优势。
另外，GPU架构向前兼容，硬件更迭随着软件不断更新适应，且软件库内就能进行直接更新。无论是台式机、笔记本、服务器，还是很大型的外设，在数据中心、边缘或者是物联网上，均可使用NVIDIA的平台。
有些公司通过去掉GPU的图形处理部分来提升AI算力和减少成本，对此Paresh Kharya表示，NVIDIA在图象处理方面本身基础就比较好，比如说其RT Core能够加速图象处理，Tensor Core做AI加速计算。
NVIDIA提供各种产品来满足客户不同需求，应用于数据中心的GPU没有图像处理部分，但有Tensor Core来做AI加速计算，还有RTX6000、RTX8000等新品兼具图像加速和AI加速功能。
Paresh Kharya认为，NVIDIA的较大优势在于可用于各种工作负载中来实现加速计算的统一架构。NVIDIA在游戏、图形、高性能计算、AI各业务板块均有很好的营收，NVIDIA可以进一步投入到我们的统一架构平台的研发当中。
在做好硬件架构的基础上，NVIDIA开发相应软件来利用硬件平台，一方面带来更大的性能提升，另一方面也降低了开发门槛。
NVIDIA与开发者保持紧密沟通与合作，以保证TensorFlow等主流开源框架与NVIDIA硬件紧密兼容，同时NVIDIA在各种软件功能和库上做沟通，使一些外部开发者可以充分利用这些东西。
以TensorFlow为例，NVIDIA尽可能将更多软件库整合到TensorFlow中，使得开发者无需关心底层，直接利用NVIDIA提供的库或新功能去开发他们想要的东西，并且可在任何NVIDIA硬件平台上使用。
三、NVIDIA为何兼容Arm做加速计算？
近期NVIDIA宣布CUDA将兼容Arm HPC，对此Paresh Kharya表示，NVIDIA希望在进入的所有加速计算领域能给客户更多选择。
Arm架构在全球范围内被广泛应用，基于Arm架构的设备约1500亿台，可提供互联、内存、CPU内核、计算能力等多元化支持。
在Paresh Kharya看来，Arm架构之所以如此成功，是因为它是一个开放平台，各类公司均可在Arm架构上进行想要的创新。
Justin Boitano补充说，NVIDIA有Arm架构许可，在边缘计算领域的汽车平台等多个硬件均基于Arm架构。Arm具有低功耗、应用灵活的特点，能满足很多客户对边缘计算的需求。
